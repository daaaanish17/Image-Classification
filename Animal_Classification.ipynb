{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxB8GZPzfYRBosJ9AfkxnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daaaanish17/Image-Classification/blob/main/Animal_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Animal Classification using Transfer Learning Model (MobileNetV2)*"
      ],
      "metadata": {
        "id": "oKOecOQaIvgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Dataset Link: https://www.kaggle.com/datasets/alessiocorrado99/animals10"
      ],
      "metadata": {
        "id": "0CohIgQGFkGT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "SOMm_d58GG9I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyplWE3yPVbF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.layers import Dense, Conv2D, GlobalAvgPool2D, Input\n",
        "from tensorflow.keras import callbacks, optimizers\n",
        "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connecting to Google Drive"
      ],
      "metadata": {
        "id": "ftnMeP22GEVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvHp-HLmTXbW",
        "outputId": "1b442c32-ab65-4a12-9252-e2d99eecd9ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my Google Drive I have already created a \"animal_classification\" folder and in this folder I have uploaded my kaggle dataset folder in zip format. "
      ],
      "metadata": {
        "id": "jvkWAkviyDCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/animal_classification/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHHlPIaGTXYY",
        "outputId": "5c7c524c-e640-4cb9-d666-c7fff5aba610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/animal_classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzipping archivee folder(image folder)\n",
        "\n",
        "!unzip archivee.zipy"
      ],
      "metadata": {
        "id": "RhkrmcS6TXVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Python Dictionary present in animal_classification folder for renaming folders"
      ],
      "metadata": {
        "id": "j3hMmqpdF8Yn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from translate import translate\n",
        "\n",
        "translate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLdpLn8VDgfD",
        "outputId": "71a2c3b1-4a58-4aac-b14f-246a03dd59e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cane': 'dog',\n",
              " 'cavallo': 'horse',\n",
              " 'elefante': 'elephant',\n",
              " 'farfalla': 'butterfly',\n",
              " 'gallina': 'chicken',\n",
              " 'gatto': 'cat',\n",
              " 'mucca': 'cow',\n",
              " 'pecora': 'sheep',\n",
              " 'scoiattolo': 'squirrel',\n",
              " 'dog': 'cane',\n",
              " 'elephant': 'elefante',\n",
              " 'butterfly': 'farfalla',\n",
              " 'chicken': 'gallina',\n",
              " 'cat': 'gatto',\n",
              " 'cow': 'mucca',\n",
              " 'spider': 'ragno',\n",
              " 'squirrel': 'scoiattolo'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renaming folder names"
      ],
      "metadata": {
        "id": "gwooViUYF2TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir('raw-img'):\n",
        "  os.rename('raw-img/' + i, 'raw-img/' + translate[i])\n",
        "\n",
        "# os.rename('raw-img/ragno',  'raw-img/spider')  "
      ],
      "metadata": {
        "id": "TAbE7rrtTXTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.rename('raw-img/ragno',  'raw-img/spider')  \n",
        "os.rename('raw-img/scoiattolo',  'raw-img/squirrel')"
      ],
      "metadata": {
        "id": "PwbD_asuFWDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.rename('raw-img/gatto',  'raw-img/cat')"
      ],
      "metadata": {
        "id": "zIGrqMc5FWAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying folder names"
      ],
      "metadata": {
        "id": "OjrztTGOyoZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir('raw-img'):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7t1DGIjFplN",
        "outputId": "ecff29a3-ec91-4158-b90b-fbf8588534c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog\n",
            "horse\n",
            "elephant\n",
            "butterfly\n",
            "chicken\n",
            "cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Displaying No. of Images in each folder"
      ],
      "metadata": {
        "id": "4twowJ8uITl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir('raw-img'):\n",
        "  print(i, len(os.listdir('raw-img/' + i)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0VfIvnXGmQ3",
        "outputId": "dd208cd9-5d82-4625-dea7-5766e589688a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dog 4863\n",
            "horse 2623\n",
            "elephant 1446\n",
            "butterfly 2112\n",
            "chicken 3098\n",
            "cat 1688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating new directories\n",
        "\n",
        "And Entering data in new directories"
      ],
      "metadata": {
        "id": "dh7imKHjHjcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('train')\n",
        "os.mkdir('test')\n",
        "\n",
        "for i in os.listdir('raw-img'):\n",
        "  os.mkdir('train/' + i)\n",
        "  os.mkdir('test/' + i)\n",
        "\n",
        "  for j in os.listdir('raw-img/'+i)[:1000]:    \n",
        "    os.rename('raw-img/'+i+'/'+j, 'train/'+i+'/'+j)\n",
        "  for j in os.listdir('raw-img/'+i)[:400]:\n",
        "    os.rename('raw-img/'+i+'/'+j, 'test/'+i+'/'+j)\n",
        "\n",
        "  #train dataset contains 1000 images while test dataset contains 400 images  "
      ],
      "metadata": {
        "id": "9hOdC2icHVaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating function for Image Data Generator."
      ],
      "metadata": {
        "id": "jzMh9Ah6bp-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_data(dir_path, target_size, batch, class_lst, pre_processs):\n",
        "  if pre_processs:\n",
        "    generate_object = ImageDataGenerator(preprocessing_function=pre_processs)\n",
        "  else:\n",
        "    generate_object = ImageDataGenerator()\n",
        "   \n",
        "  return (generate_object.flow_from_directory(dir_path, target_size=target_size, batch_size=batch,  #using flow_from_directory because all of our data is saved in form of directories.\n",
        "                                              class_mode='sparse', classes=class_lst, shuffle=True))  "
      ],
      "metadata": {
        "id": "znZhBvqgHVWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = img_data('train', (224, 224), 500, os.listdir('train'), preprocess_input)\n",
        "# mobilenet. preprocess_input will scale input pixels between -1 and 1. input_shape: Optional shape tuple, \n",
        "# only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) \n",
        "# (with channels_last data format) or (3, 224, 224) (with channels_first data format).\n",
        "\n",
        "valid_data_gen = img_data('test', (224, 224), 500, os.listdir('test'), preprocess_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDDfbij0HVUa",
        "outputId": "fc9edd0f-2332-485c-a207-e90228be570c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6000 images belonging to 6 classes.\n",
            "Found 2400 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning With MobileNet V2. MobileNet V2 model was developed at Google, pre-trained on the ImageNet dataset with 1.4M images and 1000 classes of web images. *We will use this as our base model* to train with our dataset and classify the images of animals"
      ],
      "metadata": {
        "id": "HlBly8J9X7FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    alpha=1.0,\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax',\n",
        ")"
      ],
      "metadata": {
        "id": "OAEjdONsHVSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze the convolutional base\n",
        "\n",
        "It is important to freeze the convolutional base before you compile and train the model. Freezing (by setting layer.trainable = False) prevents the weights in a given layer from being updated during training. MobileNet V2 has many layers, so setting the entire model's trainable flag to False will freeze all of them."
      ],
      "metadata": {
        "id": "UmKamG8IZN7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable=False"
      ],
      "metadata": {
        "id": "PB4J7qoLHVLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating our Image Classification Model"
      ],
      "metadata": {
        "id": "G5z9OflOZZ0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAvgPool2D())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))"
      ],
      "metadata": {
        "id": "f3gv3NM9HVIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aHDCNLdtSX2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This callback will stop the training when there is no improvement in # the loss for three consecutive epochs.\n",
        "\n",
        "elst = callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')"
      ],
      "metadata": {
        "id": "lahH7-BgSXy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ModelCheckpoint callback allows you to continually save the model both during and at the end of training. \n",
        "# Model will saved in our drive ('MyDrive/animal_classification')\n",
        "\n",
        "save_ck = callbacks.ModelCheckpoint('.mdl_wt.hdf5', save_best_only=True, monitor='val_loss', mode='min') "
      ],
      "metadata": {
        "id": "IBH2cDaBaMWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_gen, batch_size=500, validation_data=valid_data_gen, callbacks=[elst, save_ck], epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yHkaomTU8wT",
        "outputId": "579456fc-7565-480f-bff8-f51bb66237a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 5281s 447s/step - loss: 0.5057 - accuracy: 0.8192 - val_loss: 0.1670 - val_accuracy: 0.9513\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 42s 4s/step - loss: 0.0970 - accuracy: 0.9703 - val_loss: 0.1346 - val_accuracy: 0.9567\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 41s 3s/step - loss: 0.0579 - accuracy: 0.9813 - val_loss: 0.0936 - val_accuracy: 0.9704\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 42s 4s/step - loss: 0.0381 - accuracy: 0.9877 - val_loss: 0.0912 - val_accuracy: 0.9708\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 42s 3s/step - loss: 0.0236 - accuracy: 0.9945 - val_loss: 0.0900 - val_accuracy: 0.9708\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 43s 4s/step - loss: 0.0161 - accuracy: 0.9980 - val_loss: 0.0859 - val_accuracy: 0.9717\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 40s 3s/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.0870 - val_accuracy: 0.9708\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 39s 3s/step - loss: 0.0092 - accuracy: 0.9993 - val_loss: 0.0878 - val_accuracy: 0.9712\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 40s 3s/step - loss: 0.0074 - accuracy: 0.9997 - val_loss: 0.0877 - val_accuracy: 0.9717\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 42s 4s/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0869 - val_accuracy: 0.9712\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f768cea0290>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}